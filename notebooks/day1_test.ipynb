{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b28f0c8d-b524-416a-8a51-b00c3ba43a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üå± AgriGenAI - Day 1: Phenotype Feature Extraction\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "AgriGenAI - Day 1: Phenotype Feature Extraction\n",
    "================================================\n",
    "Goal: Extract visual phenotype features from tomato plant images\n",
    "Time: 8 hours\n",
    "\n",
    "What this does:\n",
    "1. Loads PlantVillage + Laboro datasets\n",
    "2. Uses ResNet50 (pretrained) to extract 2048-dim feature vectors\n",
    "3. Saves features + metadata\n",
    "4. Visualizes feature distributions\n",
    "\n",
    "NO TRAINING - Just feature extraction!\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üå± AgriGenAI - Day 1: Phenotype Feature Extraction\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6203b69-5a28-4419-bbdf-8ef19b9688c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Output directories created at: ..\\AgriGenAI_Output\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 1. PROJECT SETUP\n",
    "# ============================================\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration for Day 1\"\"\"\n",
    "    BASE_PATH = Path('../AgriGenAI_Dataset')\n",
    "    OUTPUT_PATH = Path('../AgriGenAI_Output')\n",
    "    \n",
    "    # Dataset paths\n",
    "    PLANTVILLAGE_PATH = BASE_PATH / 'PlantVillage' / 'images'\n",
    "    LABORO_PATH = BASE_PATH / 'Laboro' / 'images'\n",
    "    \n",
    "    # Output paths\n",
    "    FEATURES_PATH = OUTPUT_PATH / 'features'\n",
    "    METADATA_PATH = OUTPUT_PATH / 'metadata'\n",
    "    VISUALIZATIONS_PATH = OUTPUT_PATH / 'visualizations'\n",
    "    \n",
    "    # Model config\n",
    "    IMG_SIZE = (224, 224)\n",
    "    BATCH_SIZE = 32\n",
    "    FEATURE_DIM = 2048  # ResNet50 output\n",
    "    \n",
    "    # Sampling (for quick testing)\n",
    "    SAMPLE_SIZE = None  # Set to 100 for quick test, None for full dataset\n",
    "\n",
    "# Create output directories\n",
    "for path in [Config.FEATURES_PATH, Config.METADATA_PATH, Config.VISUALIZATIONS_PATH]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Output directories created at: {Config.OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80c88c75-e830-4e66-a38c-ded4d533fa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    }
   ],
   "source": [
    "print(Config.PLANTVILLAGE_PATH.exists(), Config.LABORO_PATH.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1322f3ae-7c1d-4e69-962c-15ce7cf31c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 2. DATA LOADER\n",
    "# ============================================\n",
    "\n",
    "\n",
    "class TomatoDatasetLoader:\n",
    "    \"\"\"Load and organize tomato images from multiple sources\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.image_data = []\n",
    "    \n",
    "    def load_plantvillage(self):\n",
    "        \"\"\"Load PlantVillage tomato leaf images\"\"\"\n",
    "        print(\"\\nüìÇ Loading PlantVillage dataset...\")\n",
    "        \n",
    "        pv_path = self.config.PLANTVILLAGE_PATH\n",
    "        if not pv_path.exists():\n",
    "            print(f\"‚ö†Ô∏è  PlantVillage path not found: {pv_path}\")\n",
    "            return 0\n",
    "        \n",
    "        count = 0\n",
    "        for disease_folder in pv_path.iterdir():\n",
    "            if disease_folder.is_dir():\n",
    "                disease_name = disease_folder.name\n",
    "                for img_file in disease_folder.glob('*.jpg'):\n",
    "                    self.image_data.append({\n",
    "                        'image_path': str(img_file),\n",
    "                        'source': 'PlantVillage',\n",
    "                        'category': disease_name,\n",
    "                        'organ': 'leaf'\n",
    "                    })\n",
    "                    count += 1\n",
    "        \n",
    "        print(f\"‚úÖ Loaded {count} PlantVillage images\")\n",
    "        return count\n",
    "    \n",
    "    def load_laboro(self):\n",
    "        \"\"\"Load Laboro tomato fruit images\"\"\"\n",
    "        print(\"\\nüìÇ Loading Laboro dataset...\")\n",
    "        \n",
    "        laboro_path = self.config.LABORO_PATH\n",
    "        if not laboro_path.exists():\n",
    "            print(f\"‚ö†Ô∏è  Laboro path not found: {laboro_path}\")\n",
    "            return 0\n",
    "        \n",
    "        count = 0\n",
    "        for img_file in laboro_path.glob('*.jpg'):\n",
    "            self.image_data.append({\n",
    "                'image_path': str(img_file),\n",
    "                'source': 'Laboro',\n",
    "                'category': 'fruit_detection',\n",
    "                'organ': 'fruit'\n",
    "            })\n",
    "            count += 1\n",
    "        \n",
    "        print(f\"‚úÖ Loaded {count} Laboro images\")\n",
    "        return count\n",
    "    \n",
    "    def load_all(self):\n",
    "        \"\"\"Load all datasets\"\"\"\n",
    "        pv_count = self.load_plantvillage()\n",
    "        lab_count = self.load_laboro()\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(self.image_data)\n",
    "        \n",
    "        # Sample if needed\n",
    "        if self.config.SAMPLE_SIZE:\n",
    "            df = df.sample(n=min(self.config.SAMPLE_SIZE, len(df)), random_state=42)\n",
    "            print(f\"\\n‚ö†Ô∏è  Using sample of {len(df)} images for quick testing\")\n",
    "        \n",
    "        print(f\"\\nüìä Total dataset: {len(df)} images\")\n",
    "        print(f\"   - PlantVillage (leaves): {len(df[df['source']=='PlantVillage'])}\")\n",
    "        print(f\"   - Laboro (fruits): {len(df[df['source']=='Laboro'])}\")\n",
    "        \n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d056cf0d-37e2-437d-9d20-9dcdf55bf950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 3. CNN FEATURE EXTRACTOR\n",
    "# ============================================\n",
    "\n",
    "\n",
    "class PhenotypeFeatureExtractor:\n",
    "    \"\"\"Extract phenotype features using pretrained ResNet50\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        print(\"\\nüîß Loading ResNet50 model (pretrained on ImageNet)...\")\n",
    "        \n",
    "        # Load ResNet50 WITHOUT top classification layer\n",
    "        self.model = ResNet50(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            pooling='avg',\n",
    "            input_shape=(224, 224, 3)\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ ResNet50 loaded. Output shape: {self.model.output_shape}\")\n",
    "        print(\"   This will extract 2048-dimensional feature vectors\")\n",
    "    \n",
    "    def preprocess_image(self, img_path):\n",
    "        \"\"\"Load and preprocess single image\"\"\"\n",
    "        try:\n",
    "            img = image.load_img(img_path, target_size=self.config.IMG_SIZE)\n",
    "            img_array = image.img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            img_array = preprocess_input(img_array)\n",
    "            return img_array\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading {img_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_features_batch(self, image_paths):\n",
    "        \"\"\"Extract features for a batch of images\"\"\"\n",
    "        batch_arrays = []\n",
    "        valid_paths = []\n",
    "        \n",
    "        for img_path in image_paths:\n",
    "            img_array = self.preprocess_image(img_path)\n",
    "            if img_array is not None:\n",
    "                batch_arrays.append(img_array)\n",
    "                valid_paths.append(img_path)\n",
    "        \n",
    "        if not batch_arrays:\n",
    "            return None, valid_paths\n",
    "        \n",
    "        # Stack and predict\n",
    "        batch_arrays = np.vstack(batch_arrays)\n",
    "        features = self.model.predict(batch_arrays, verbose=0)\n",
    "        \n",
    "        return features, valid_paths\n",
    "    \n",
    "    def extract_all_features(self, df):\n",
    "        \"\"\"Extract features for all images with progress bar\"\"\"\n",
    "        print(\"\\nüöÄ Extracting phenotype features from all images...\")\n",
    "        print(f\"   Processing {len(df)} images in batches of {self.config.BATCH_SIZE}\")\n",
    "        \n",
    "        all_features = []\n",
    "        all_paths = []\n",
    "        \n",
    "        # Process in batches\n",
    "        for i in tqdm(range(0, len(df), self.config.BATCH_SIZE)):\n",
    "            batch_df = df.iloc[i:i+self.config.BATCH_SIZE]\n",
    "            batch_paths = batch_df['image_path'].tolist()\n",
    "            \n",
    "            features, valid_paths = self.extract_features_batch(batch_paths)\n",
    "            \n",
    "            if features is not None:\n",
    "                all_features.append(features)\n",
    "                all_paths.extend(valid_paths)\n",
    "        \n",
    "        # Combine all features\n",
    "        if all_features:\n",
    "            all_features = np.vstack(all_features)\n",
    "            print(f\"\\n‚úÖ Feature extraction complete!\")\n",
    "            print(f\"   Shape: {all_features.shape}\")\n",
    "            print(f\"   Successfully processed: {len(all_paths)}/{len(df)} images\")\n",
    "            return all_features, all_paths\n",
    "        else:\n",
    "            print(\"‚ùå No features extracted!\")\n",
    "            return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1250b1c-5bbd-460c-9140-b9006fe59ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 4. FEATURE ANALYSIS & VISUALIZATION\n",
    "# ============================================\n",
    "\n",
    "class FeatureVisualizer:\n",
    "    \"\"\"Visualize extracted features\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "    \n",
    "    def plot_feature_distribution(self, features, df):\n",
    "        \"\"\"Plot distribution of feature values\"\"\"\n",
    "        print(\"\\nüìä Creating feature distribution plot...\")\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Plot 1: Feature mean distribution\n",
    "        plt.subplot(1, 2, 1)\n",
    "        feature_means = features.mean(axis=0)\n",
    "        plt.hist(feature_means, bins=50, color='green', alpha=0.7)\n",
    "        plt.xlabel('Feature Value')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Distribution of Feature Means')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Feature std distribution\n",
    "        plt.subplot(1, 2, 2)\n",
    "        feature_stds = features.std(axis=0)\n",
    "        plt.hist(feature_stds, bins=50, color='blue', alpha=0.7)\n",
    "        plt.xlabel('Standard Deviation')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Distribution of Feature Std Dev')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        save_path = self.config.VISUALIZATIONS_PATH / 'feature_distribution.png'\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"‚úÖ Saved: {save_path}\")\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_pca(self, features, df):\n",
    "        \"\"\"Reduce dimensions with PCA and visualize\"\"\"\n",
    "        print(\"\\nüìä Creating PCA visualization...\")\n",
    "        \n",
    "        # Apply PCA\n",
    "        pca = PCA(n_components=2)\n",
    "        features_2d = pca.fit_transform(features)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # Color by source\n",
    "        for source in df['source'].unique():\n",
    "            mask = df['source'] == source\n",
    "            plt.scatter(\n",
    "                features_2d[mask, 0],\n",
    "                features_2d[mask, 1],\n",
    "                label=source,\n",
    "                alpha=0.6,\n",
    "                s=20\n",
    "            )\n",
    "        \n",
    "        plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "        plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "        plt.title('PCA: Phenotype Feature Space')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        save_path = self.config.VISUALIZATIONS_PATH / 'pca_visualization.png'\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"‚úÖ Saved: {save_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        return pca\n",
    "    \n",
    "    def plot_tsne(self, features, df, sample_size=1000):\n",
    "        \"\"\"Reduce dimensions with t-SNE and visualize\"\"\"\n",
    "        print(\"\\nüìä Creating t-SNE visualization...\")\n",
    "        \n",
    "        # Sample if too large\n",
    "        if len(features) > sample_size:\n",
    "            indices = np.random.choice(len(features), sample_size, replace=False)\n",
    "            features_sample = features[indices]\n",
    "            df_sample = df.iloc[indices]\n",
    "            print(f\"   Using {sample_size} samples for t-SNE (computational efficiency)\")\n",
    "        else:\n",
    "            features_sample = features\n",
    "            df_sample = df\n",
    "        \n",
    "        # Apply t-SNE\n",
    "        tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "        features_2d = tsne.fit_transform(features_sample)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # Color by organ type\n",
    "        for organ in df_sample['organ'].unique():\n",
    "            mask = df_sample['organ'] == organ\n",
    "            plt.scatter(\n",
    "                features_2d[mask, 0],\n",
    "                features_2d[mask, 1],\n",
    "                label=organ,\n",
    "                alpha=0.6,\n",
    "                s=20\n",
    "            )\n",
    "        \n",
    "        plt.xlabel('t-SNE Dimension 1')\n",
    "        plt.ylabel('t-SNE Dimension 2')\n",
    "        plt.title('t-SNE: Phenotype Feature Clustering')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        save_path = self.config.VISUALIZATIONS_PATH / 'tsne_visualization.png'\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"‚úÖ Saved: {save_path}\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b72c3f2f-00b4-4122-9feb-2b6708e4a637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 5. SAVE OUTPUTS\n",
    "# ============================================\n",
    "\n",
    "def save_features_and_metadata(features, df, config):\n",
    "    \"\"\"Save extracted features and metadata\"\"\"\n",
    "    print(\"\\nüíæ Saving features and metadata...\")\n",
    "    \n",
    "    # Save features as numpy array\n",
    "    features_file = config.FEATURES_PATH / 'phenotype_features.npy'\n",
    "    np.save(features_file, features)\n",
    "    print(f\"‚úÖ Features saved: {features_file}\")\n",
    "    print(f\"   Shape: {features.shape}\")\n",
    "    \n",
    "    # Save metadata as CSV\n",
    "    metadata_file = config.METADATA_PATH / 'image_metadata.csv'\n",
    "    df.to_csv(metadata_file, index=False)\n",
    "    print(f\"‚úÖ Metadata saved: {metadata_file}\")\n",
    "    print(f\"   Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Save feature statistics\n",
    "    stats = {\n",
    "        'mean': features.mean(axis=0),\n",
    "        'std': features.std(axis=0),\n",
    "        'min': features.min(axis=0),\n",
    "        'max': features.max(axis=0)\n",
    "    }\n",
    "    stats_file = config.FEATURES_PATH / 'feature_statistics.npz'\n",
    "    np.savez(stats_file, **stats)\n",
    "    print(f\"‚úÖ Statistics saved: {stats_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2fbb3a4-84c3-4da9-b906-ab6d85d3f328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STARTING DAY 1 PIPELINE\n",
      "============================================================\n",
      "\n",
      "üìÇ Loading PlantVillage dataset...\n",
      "‚úÖ Loaded 14509 PlantVillage images\n",
      "\n",
      "üìÇ Loading Laboro dataset...\n",
      "‚úÖ Loaded 804 Laboro images\n",
      "\n",
      "üìä Total dataset: 15313 images\n",
      "   - PlantVillage (leaves): 14509\n",
      "   - Laboro (fruits): 804\n",
      "\n",
      "üîß Loading ResNet50 model (pretrained on ImageNet)...\n",
      "‚úÖ ResNet50 loaded. Output shape: (None, 2048)\n",
      "   This will extract 2048-dimensional feature vectors\n",
      "\n",
      "üöÄ Extracting phenotype features from all images...\n",
      "   Processing 15313 images in batches of 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 479/479 [1:06:32<00:00,  8.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Feature extraction complete!\n",
      "   Shape: (15313, 2048)\n",
      "   Successfully processed: 15313/15313 images\n",
      "\n",
      "üìä Creating feature distribution plot...\n",
      "‚úÖ Saved: ..\\AgriGenAI_Output\\visualizations\\feature_distribution.png\n",
      "\n",
      "üìä Creating PCA visualization...\n",
      "‚úÖ Saved: ..\\AgriGenAI_Output\\visualizations\\pca_visualization.png\n",
      "\n",
      "üìä Creating t-SNE visualization...\n",
      "   Using 1000 samples for t-SNE (computational efficiency)\n",
      "‚úÖ Saved: ..\\AgriGenAI_Output\\visualizations\\tsne_visualization.png\n",
      "\n",
      "üíæ Saving features and metadata...\n",
      "‚úÖ Features saved: ..\\AgriGenAI_Output\\features\\phenotype_features.npy\n",
      "   Shape: (15313, 2048)\n",
      "‚úÖ Metadata saved: ..\\AgriGenAI_Output\\metadata\\image_metadata.csv\n",
      "   Columns: ['image_path', 'source', 'category', 'organ']\n",
      "‚úÖ Statistics saved: ..\\AgriGenAI_Output\\features\\feature_statistics.npz\n",
      "\n",
      "============================================================\n",
      "‚úÖ DAY 1 COMPLETE!\n",
      "============================================================\n",
      "\n",
      "üìä Summary:\n",
      "   - Total images processed: 15313\n",
      "   - Feature vectors extracted: 15313\n",
      "   - Feature dimensions: 2048\n",
      "   - PlantVillage (leaves): 14509\n",
      "   - Laboro (fruits): 804\n",
      "\n",
      "üìÅ Outputs saved in: ..\\AgriGenAI_Output\n",
      "   - Features: phenotype_features.npy\n",
      "   - Metadata: image_metadata.csv\n",
      "   - Visualizations: 3 PNG files\n",
      "\n",
      "üöÄ Ready for Day 2: Genotype-Trait Mapping!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 6. MAIN EXECUTION\n",
    "# ============================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run Day 1 pipeline\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STARTING DAY 1 PIPELINE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    config = Config()\n",
    "    \n",
    "    # Step 1: Load datasets\n",
    "    loader = TomatoDatasetLoader(config)\n",
    "    df = loader.load_all()\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        print(\"‚ùå No images found! Check your dataset paths.\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: Extract features\n",
    "    extractor = PhenotypeFeatureExtractor(config)\n",
    "    features, valid_paths = extractor.extract_all_features(df)\n",
    "    \n",
    "    if features is None:\n",
    "        print(\"‚ùå Feature extraction failed!\")\n",
    "        return\n",
    "    \n",
    "    # Filter dataframe to only valid images\n",
    "    df = df[df['image_path'].isin(valid_paths)].reset_index(drop=True)\n",
    "    \n",
    "    # Step 3: Visualize\n",
    "    visualizer = FeatureVisualizer(config)\n",
    "    visualizer.plot_feature_distribution(features, df)\n",
    "    pca = visualizer.plot_pca(features, df)\n",
    "    visualizer.plot_tsne(features, df)\n",
    "    \n",
    "    # Step 4: Save outputs\n",
    "    save_features_and_metadata(features, df, config)\n",
    "    \n",
    "    # Final summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ DAY 1 COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nüìä Summary:\")\n",
    "    print(f\"   - Total images processed: {len(df)}\")\n",
    "    print(f\"   - Feature vectors extracted: {features.shape[0]}\")\n",
    "    print(f\"   - Feature dimensions: {features.shape[1]}\")\n",
    "    print(f\"   - PlantVillage (leaves): {len(df[df['source']=='PlantVillage'])}\")\n",
    "    print(f\"   - Laboro (fruits): {len(df[df['source']=='Laboro'])}\")\n",
    "    print(f\"\\nüìÅ Outputs saved in: {config.OUTPUT_PATH}\")\n",
    "    print(f\"   - Features: phenotype_features.npy\")\n",
    "    print(f\"   - Metadata: image_metadata.csv\")\n",
    "    print(f\"   - Visualizations: 3 PNG files\")\n",
    "    print(f\"\\nüöÄ Ready for Day 2: Genotype-Trait Mapping!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f145e-6eba-4ad8-9b37-b9fed24603c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfenv)",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
